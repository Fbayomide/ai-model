# -*- coding: utf-8 -*-
"""forecast_house_model_main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CRhJ73WJbMKRQjEHFYWyYtkqZUJYSMTp
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

listed_homes = []


for i in range(1, 2000):
  url= f'https://www.propertypro.ng/property-for-rent/page={i}'
  headers ={'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'}
  res = requests.get(url,headers=headers)

  pro_soup = BeautifulSoup(res.content, 'html.parser')
  homes = pro_soup.find_all('div', class_='single-room-sale listings-property')
  #extract information needed from website

  for home in homes:

    # extract date
    day_ = home.find('h5').get_text(strip=True)
    days= []

    def extract_days(x):
      extract_day = x.split(',')
      length_ = len(extract_day)

      if length_ < 2:
        days.append(extract_day[0])
      else:
        days.append(extract_day[1])
      return days

    days = extract_days(day_)
    # extract date from days text
    for day in days:
      # print(day)
      ext = re.search(r"(\d{2} \w+ \d{4})", day).group(0)



    # home description is same tag h4 with location
    # description is index 0
    tag = home.find_all('h4')
    desc = tag[0].get_text()

    # location has same tag h4 name with desc
    loc = tag[1].get_text(strip=True)


    # type of apartment and price is in same h3 tag
    # type of apartment
    tag_1 = home.find_all('h3')
    type_= tag_1[0].get_text()


    # price, currency and payment type (year, monthly, sqm)
    amount = tag_1[1].get_text()
    currency = re.search(r'\$|â‚¦', amount).group(0)
    price = re.search(r'[\d,]+', amount).group(0)
    # payment_type = re.search(r'/\w+', amount)
    # payment= np.nan if payment_type == None else payment_type.group(0).replace('/', '')


    # number of bedrooms
    span_= home.find_all('span')
    num_of_beds = []
    result= ''
    # print(span_len)
    def extract_span(x):
      span_len= len(x)

      if span_len < 7:
         result= span_[2].get_text()
      elif span_len == 7:
        result = span_[4].get_text()
      else:
        result = span_[5].get_text()

      num_of_beds.append(result)
      return result

    num_of_bed = extract_span(span_)


    # if there is an error here with the first num of beds
    # modify code with checking for span length
    # if less than 7, the span_ index for beds is in index 3
    # span_length = len(span_)

    # extract type of furnishing
    furnished_ = home.find('div', class_='furnished-btn').find_all('a')
    furnished = []
    furnishes= []
    len_fur = len(furnished_)
    [furnished.extend(list_) for list_ in furnished_ if len_fur > 0]
    def check_list(lst):
      if len(lst) == 0:
        return 'NaN'
      elif len_fur == 1:
        return furnished[0]
      else:
        return str(furnished[0]) + ' ' + '&' + ' ' + str(furnished[1])
    furnishes = check_list(furnished)

    # print(loc)
    listed_homes.append([ext, desc, type_,loc, num_of_bed, furnishes, currency, price])

df= pd.DataFrame(listed_homes, columns= ['Date', 'Description', 'Type', 'Location', 'Number Of Bedrooms', 'Furnished', 'Currency','Price'])
df.tail()

df.to_csv('forecast_house_pro_Data.csv')

from google.colab import drive
drive.mount('/content/drive')

df= pd.read_csv('/content/forecast_house_pro_Data.csv')

df.head()

df.isnull().sum()

df['Date'] = pd.to_datetime(df['Date'])

df['Price'] = df['Price'].astype(str).str.replace(',', '')

df['Price'] = df['Price'].astype(int)

for index, row in df.iterrows():
  if '$' in row['Currency']:
    dol_to_naira = 775.50 * int(row['Price'])
    df.loc[index, 'Price'] = dol_to_naira

df['Currency'].unique()

df['Type']= df['Type'].str.lower()

for index, row in df.iterrows():
  if 'office' in row['Type'] or 'commercial' in row['Type'] or 'shop' in row['Type']:
    df.drop(index, inplace=True)

# property_type = ['mini flat', 'flat', 'terrace duplex', 'apartment', 'semi detached duplex', 'detached duplex']

def clean_type(x):
    if 'terraces duplex' in x or 'terraced duplex' in x or 'terrace duplex' in x or 'terrace' in x:
      return 'terrace duplex'
    elif 'mini flat' in x or 'room and parlor' in x:
      return 'mini flat'
    elif 'flat' in x or 'flats' in x:
      return 'flat'
    elif 'self contain' in x or 'self con' in x:
      return 'self contain'
    elif 'apartment' in x and not 'shared' in x:
      return 'flat'
    elif 'shared' in x and 'apartment' in x:
      return 'shared apartment'
    elif 'maisonette' in x or 'massionette' in x:
      return 'maisonette'
    elif 'semi' in x and 'detached ' in x:
      return 'semi detached duplex'
    elif 'detached' in x and not 'semi' in x:
      return 'detached duplex'
    elif 'penthouse' in x:
      return 'penthouse'
    elif 'mansion' in x:
      return 'mansion'
    elif 'bungalow' in x:
      return 'bungalow'
    elif 'bedroom duplex' in x:
      return 'duplex'
    else:
      return x


df['Property_type']= df['Type'].map(clean_type)

df['Property_type'].unique()

pent = 0
for index, row in df.iterrows():
  if 'penthouse' in row['Type']:
    pent+=1
print(pent)

terrace = 0
for index, row in df.iterrows():
  if 'terrace' in row['Type'] or 'terraces' in row['Type'] or 'terraced' in row['Type']:
    terrace+=1
print(terrace)

detached = 0
for index, row in df.iterrows():
  if 'semi' in row['Type']:
    detached+=1
print(detached)

detached_ = 0
for index, row in df.iterrows():
  if 'detached' in row['Type']:
    detached_+=1
print(detached_)

for index, row in df.iterrows():
  if 'haap coliving furnished bq for monthly stay' in row['Property_type']:
    df.drop(index, inplace=True)

self_=0

for index, row in df.iterrows():
  if 'self contain' in row['Type'] or 'self con' in row['Type']:
    self_+=1
print(self_)

ware = 0

for index, row in df.iterrows():
  if 'warehouse' in row['Type']:
    df.drop(index, inplace=True)

for index, row in df.iterrows():
  if '1 room (sharing kitchen with just a single occupant)' in row['Type']:
    df.drop(index, inplace=True)

for index, row in df.iterrows():
  if 'newly built self con for rent' in row['Property_type']:
    df.loc[index, 'Property_type'] = 'studio apartment'
    # print(row)

for index, row in df.iterrows():
  if 'sqm land' in row['Property_type']:
    df.drop(index, inplace=True)

share_=0

for index, row in df.iterrows():
  if 'shared apartment' in row['Type']:
    share_+=1
print(share_)

df['Property_type'].value_counts()

plt.figure(figsize=(18,12))

property_val= df['Property_type'].value_counts()

# Create a bar plot
plt.bar(property_val.index, property_val.values)

# Set plot title and labels
plt.title('Count of Property Types')
plt.xlabel('Property Types')
plt.ylabel('Count')
plt.tight_layout()
plt.xticks(rotation=90)

# Show the plot
plt.show()

df['Number Of Bedrooms'].unique()

# bed_ = 0
for index, row in df.iterrows():
  df_bed = str(row['Number Of Bedrooms'])
  match_ = re.search(r'^\d', df_bed)
  beds= 0 if match_ == None else match_.group(0)
  df.loc[index, 'Number Of Bedrooms'] = beds
  # print(beds)

df['Number Of Bedrooms'].unique()

df["Number Of Bedrooms"]= df['Number Of Bedrooms'].astype(int)

df.dtypes

df['Furnished'].unique()

# replace nan values with non-furnished

df['Furnished'].fillna('Non-Furnished', inplace=True)

df['Furnished'].unique()

# Calculate average price for each type of furnishing

plt.figure(figsize=(18,12))
average_prices = df.groupby('Furnished')['Price'].mean()

# Create a bar plot
plt.bar(average_prices.index, average_prices.values)

# Set plot title and labels
plt.title('Average Price by Furnish Type')
plt.xlabel('Furnish Types')
plt.ylabel('Average Price')

# Show the plot
plt.show()

df['Location'].unique()

location_list = ['Chevron', 'Ikate', 'Maruwa','Ikota', 'Orchid',  'Igbo Efon', 'Ologolo',
                'Osapa London', 'Agungi', 'Nicon', 'Salem', 'Ikate-Elegushi', 'Ajah', 'Thomas Estate', 'Phase 1', 'Osapa london'
                'Olokonla', 'Abijo', 'Lafiaji', 'Sangotedo', 'Idado', 'Elf',
                'Mobil','VGC', 'Vgc','Victoria Island', 'Bodije', 'Ikeja', 'Yaba',
                 'Ibeju', 'Ikoyi', 'Ikorodu', 'Lokogoma', 'Jabi', 'Wumba',
                 'Ogba', 'Surulere', 'Shomolu', 'Kaura', 'Ketu', 'Garki 1', 'Galadimawa', 'Garki 2',
                 'Maryland', 'Agege', 'Gbagada', 'Magodo', 'Merian', 'Onikolobo', 'Akala', 'Oluyole', 'Asaye', 'Iju',
                 'Gwarinpa', 'Amuwo Odofin', 'Egbeda', 'Wuse 2', 'Wuye', 'Ilasan', 'Ajah', 'Iyanganku', 'Bodija', 'Samonda', 'Akobo', 'Maitama', 'Guzape',
                 'Asokoro', 'Jabi', 'Ojodu', 'Ipaja', 'Bariga', 'Elegushi', 'Ogudu', 'Apete', 'Toll Gate', 'Apo', 'Agodi', 'Oke Afa', 'Ajao Estate', 'Awoyaya', 'Jahi']

for index, row in df.iterrows():
  for loc_ in location_list:
    if loc_ in row['Location']:
      df.loc[index, 'Loc'] = loc_

df['Loc'].unique()

df['Loc'].value_counts()

df['Loc'].isnull().sum()

for index, row in df.iterrows():
  if 'Toll Gate' in row['Loc'] and 'Orchid' in row['Location']:
    df.loc[index, 'Loc'] = 'Orchid'
    # print(toll_split)

for index, row in df.iterrows():
  if 'Toll Gate' in row['Loc'] and 'Orchid' not in row['Location']:
    toll_split = row['Location'].split(" ")
    df.loc[index, 'Loc'] = 'Chevron'

for index, row in df.iterrows():
  if 'Yaba' in row['Loc']:
    yaba_split = row['Location'].split(" ")[0]
    df.loc[index, 'Loc'] = yaba_split
    # print(yaba_split)

for index, row in df.iterrows():
  if 'Phase 1' in row['Loc']:
    df.loc[index, 'Loc'] = 'Phase 1, Lekki'

for index, row in df.iterrows():
  if 'Ikate' in row['Loc']:
    df.loc[index, 'Loc'] = 'Ikate Lekki'

df['Loc'].value_counts()

df['Loc'].isnull().sum()

df.head()

for index, row in df.iterrows():
  df_loc= str(row['Location'])
  df_split= row['Location'].split(' ')[-1]
  df.loc[index, 'State'] = df_split

df['State'].unique()

df.head()

df.dropna(axis=0, inplace=True)

df.isnull().sum()

df.drop_duplicates()

pd.set_option('display.float_format', '{:.2f}'.format)

from sklearn.preprocessing import LabelEncoder

le_furnished= LabelEncoder()
df['Furnished'] = le_furnished.fit_transform(df['Furnished'])

le_pro = LabelEncoder()

df['Property_type'] = le_pro.fit_transform(df['Property_type'])

le_loc = LabelEncoder()
df['Loc'] = le_loc.fit_transform(df['Loc'])

le_state= LabelEncoder()
df['State']= le_state.fit_transform(df['State'])

df.head()

df['ts'] = df.Date.values.astype(np.int64) // 10 ** 9
df.head()

df.drop(columns=['Unnamed: 0','Date', 'Description', 'Type', 'Location', 'Currency'], inplace=True)

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso
X= df.drop("Price", axis=1).values
y = df["Price"].values

names = df.drop("Price", axis=1).columns
lasso = Lasso(alpha=0.1)
lasso_coef= lasso.fit(X, y).coef_
plt.bar(names, lasso_coef)
plt.xticks(rotation=90)
plt.show()

df.drop(columns=['State'], inplace=True)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score, mean_squared_error
from sklearn.model_selection import train_test_split

X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=42)

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV
from copy import deepcopy
import numpy as np
import pandas as pd
from datetime import datetime

best_fit={}

class RandomForestARModel():
        # input randomized search to define the parameters that work
    # best_fit={}

    def random_forest_tuning(X_train, y_train):

        model = RandomForestRegressor()
        grid = {'n_estimators': [100, 200, 300, 400],
              'max_depth': [2, 5, 8],
              'max_features': ['sqrt', 'log2'],
              'random_state': [42]}
        random= RandomizedSearchCV(model, grid, cv=2)
        random.fit(X_train, y_train)
        best_fit= (random.best_params_)
        return best_fit

    def __init__(self, best_fit, n_lags=1, random_state=42):
        self.n_lags = n_lags
        self.model = RandomForestRegressor(**best_fit)

    def fit(self, X_train, y_train):
        train_df = pd.DataFrame(X_train)
        self.train_df = deepcopy(train_df)

        Xtrain = pd.concat([train_df.shift(t) for t in range(1, self.n_lags + 1)], axis=1).dropna()
        self.Xtrain = Xtrain

        y_df = pd.DataFrame(y_train)
        ytrain = y_df.loc[Xtrain.index,:]
        self.ytrain = ytrain

        self.model.fit(Xtrain, ytrain.values.ravel())
        return self.model

    def sample_forecast(self,X_test, n_periods, n_samples, random_state):
        n_samples = best_fit['n_estimators']
        random_state = best_fit['random_state']
        samples = self._perform_forecast(n_periods, n_samples, random_state )
        output = self._retransform_forecast(samples, n_periods)
        return output

    def _perform_forecast(self, n_periods, n_samples, random_state):
        samples = []
        n_samples = best_fit['n_estimators']
        random_state = best_fit['random_state']
        # test_df = pd.DataFrame(X_test)
        # self.test_df = deepcopy(test_df)
        # X_test_lagged = pd.concat([test_df.shift(t) for t in range(1, self.n_lags + 1)], axis=1).dropna()

        # y_test = pd.DataFrame(y_test)
        # ytest = y_test.loc[X_test_lagged.index,:]


        np.random.seed(random_state)

        for i in range(n_samples):

           Xf = np.concatenate([self.Xtrain.iloc[-1,1:].values.reshape(1,-1),
                                 self.ytrain.iloc[-1].values.reshape(1,1)],1)
           forecasts = []

           for t in range(n_periods):
                tree = self.model.estimators_[np.random.randint(len(self.model.estimators_))]
                pred = tree.predict(Xf)[0]
                forecasts.append(pred)

                Xf = np.concatenate([Xf[:, 1:], np.array([[pred]])], 1)
                samples.append(forecasts)

        return samples

    def _retransform_forecast(self, samples, n_periods):
        full_sample_tree = []

        for samp in samples:
            draw = np.array(samp)
            result = draw

            full_sample_tree.append(result.reshape(-1, 1))

        return np.concatenate(full_sample_tree, 1)

n_periods = 1
# today = datetime.now().date()

# # next_month = today.replace(month=today.month + 3)
# timestamp_mon = int(datetime.combine(today, datetime.min.time()).timestamp())
# X_mon = np.array([[5, 'terrace duplex', 'Chevron Lekki', timestamp_mon]])
# X_mon[:, 1] = le_pro.transform(X_mon[:, 1])
# X_mon[:, 2] = le_loc.transform(X_mon[:, 2])
# X_mon = X_mon.astype(int)

best_fit = RandomForestARModel.random_forest_tuning(X_train, y_train)
model = RandomForestARModel(best_fit, n_lags=3)
model.fit(X_train,y_train)
random_state = best_fit['random_state']
n_sample = best_fit['n_estimators']
forecast_samples = model.sample_forecast(X_test, n_periods,n_sample, random_state)
print(forecast_samples)

today = datetime.now().date()
today_year = today.year
today_month = today.month
today_day = today.day
d_day = datetime(today_year, today_month, today_day)

next = today.replace(month=today.month + 3)
next_year = next.year
next_mon = next.month
next_day = next.day
future = datetime(next_year, next_mon, next_day)
difference = future - d_day
n_periods = difference.days - 2

timestamp_mon = int(datetime.combine(next, datetime.min.time()).timestamp())
X_mon = np.array([[5, 'Serviced & Newly Built', 'terrace duplex', 'Chevron', timestamp_mon]])
X_mon[:, 1] = le_furnished.transform(X_mon[:,1])
X_mon[:, 2] = le_pro.transform(X_mon[:, 2])
X_mon[:, 3] = le_loc.transform(X_mon[:, 3])
X_mon = X_mon.astype(int)


forecast_three = model.sample_forecast(X_mon, n_periods,n_sample, random_state)
means_three = np.mean(forecast_three,axis = 1)
lowers_ = np.quantile(forecast_three,0.05,1)
uppers_ = np.quantile(forecast_three,0.95,1)

# print(forecast_[0])
print(np.mean((means_three)))
print(min(lowers_))
print(max(uppers_))
print(n_periods)

rmse_three = np.sqrt(np.mean((forecast_three - means_three[:, np.newaxis])**2, axis=0))
print(np.mean(rmse_three))

# mean for today
# mean in 90 dates
# mean in 30 days
# mean in 60 days
# train and test date
# rmse result
# each mean value for

today = datetime.now().date()
today_year = today.year
today_month = today.month
today_day = today.day
d_day = datetime(today_year, today_month, today_day)

next = today.replace(month=today.month + 2)
next_year = next.year
next_mon = next.month
next_day = next.day
future = datetime(next_year, next_mon, next_day)
difference = future - d_day
n_periods = difference.days - 1

X_mon = np.array([[5, 'Serviced & Newly Built', 'terrace duplex', 'Chevron', timestamp_mon]])
X_mon[:, 1] = le_furnished.transform(X_mon[:,1])
X_mon[:, 2] = le_pro.transform(X_mon[:, 2])
X_mon[:, 3] = le_loc.transform(X_mon[:, 3])
X_mon = X_mon.astype(int)


forecast_two = model.sample_forecast(X_mon, n_periods,n_sample, random_state)
means_two = np.mean(forecast_two,1)
lowers_ = np.quantile(forecast_two,0.05,1)
uppers_ = np.quantile(forecast_two,0.95,1)

# print(forecast_two)
print(np.mean((means_two)))
print(min(lowers_))
print(max(uppers_))
print(n_periods)

today = datetime.now().date()
today_year = today.year
today_month = today.month
today_day = today.day
d_day = datetime(today_year, today_month, today_day)

next = today.replace(month=today.month + 1)
next_year = next.year
next_mon = next.month
next_day = next.day
future = datetime(next_year, next_mon, next_day)
difference = future - d_day
n_periods = difference.days - 1

X_mon = np.array([[5, 'Serviced & Newly Built', 'terrace duplex', 'Chevron', timestamp_mon]])
X_mon[:, 1] = le_furnished.transform(X_mon[:,1])
X_mon[:, 2] = le_pro.transform(X_mon[:, 2])
X_mon[:, 3] = le_loc.transform(X_mon[:, 3])
X_mon = X_mon.astype(int)


forecast_ = model.sample_forecast(X_mon, n_periods,n_sample, random_state)
means_one = np.mean(forecast_,1)
lowers_ = np.quantile(forecast_,0.05,1)
uppers_ = np.quantile(forecast_,0.95,1)
rmse_one = np.sqrt(np.mean((forecast_ - means_one[:, np.newaxis])**2, axis=0))

# print(forecast_[0])
print(np.mean((means_one)))
print(min(lowers_))
print(max(uppers_))
print(n_periods)
print(np.mean(rmse_one))